= Create a Custom Token Filter 
:page-topic-type: guide
:page-ui-name: {ui-name}
:page-product-name: {product-name}
:description: Create a custom token filter with the Couchbase {page-ui-name} to change how the Search Service creates tokens from Search index content and Search queries.
:page-toclevels: 3

[abstract]
{description}

xref:customize-index.adoc#token-filters[Token filters] can improve your search results by removing characters from your Search index or Search queries that prevent matches. 

== Prerequisites 

* You have the Search Service enabled on a node in your database.
For more information about how to change Services on your database, see xref:cloud:clusters:modify-database.adoc[].
 
* You have logged in to the Couchbase {page-ui-name}. 

* You have started to create or already created an index in xref:create-search-index-ui.adoc[Advanced Mode].

== Procedure 

To create a custom token filter with the {page-ui-name} in Advanced Mode: 

. On the *Databases* page, select the database that has the Search index you want to edit. 
. Go to menu:Data Tools[Search].
. Click the index where you want to create a custom token filter.
. Under *Advanced Settings*, expand *Custom Filters*. 
+
NOTE: Make sure you use *Advanced Mode*. 
. Click btn:[Add Token Filter].
. In the *Name* field, enter a name for the token filter.

You can create any of the following custom token filters: 

|====
| Token Filter Type | Description

| <<dict-compound,dict_compound>>
| Use a wordlist to find and create tokens from compound words in existing tokens.

| <<edge-ngram,edge_ngram>>
| Use a set character length to create tokens from the start or end of existing tokens.

| <<elision,elision>>
| Use a wordlist to remove elisions from input tokens.

| <<keyword-marker,keyword_marker>> 
| Use a wordlist of keywords to find and create new tokens.

| <<length,length>>
| Use a set character length to filter out tokens that are too long or too short.

| <<ngram,ngram>>
| Use a set character length to create new tokens.

| <<normalize-unicode,normalize_unicode>>
| Use Unicode Normalization to convert tokens.

| <<shingle,shingle>>
| Use a set character length and separator to concatenate and create new tokens.

| <<stop-tokens,stop_tokens>>
| Use a wordlist to find and remove words from tokens.

| <<truncate-token,truncate_token>>
| Use a set character length to truncate existing tokens.

|====

[#dict-compound]
=== Create a Custom `dict_compound` Token Filter

include::partial$custom-token-filters-descriptions.adoc[tags=dict;!dict_example]

To create a new `dict_compound` token filter with the {page-ui-name} in Advanced Mode:
 
. In the *Type* list, select *dict_compound*. 
. In the *Sub Words* list, select the wordlist to use to find subwords in input tokens.
+
You can choose your own xref:create-custom-wordlist.adoc[custom wordlist] or a xref:default-wordlists-reference.adoc[default wordlist]. Each subword match creates a new token. 
. Click btn:[Submit]. 

[#edge-ngram]
=== Create a Custom `edge_ngram` Token Filter 
include::partial$custom-token-filters-descriptions.adoc[tags=edge;!edge_example]

To create a new `edge_ngram` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *edge_ngram*.
. Do one of the following: 
.. To create new tokens starting from the end of input tokens, select *Back*. 
.. To create new tokens starting from the beginning of input tokens, clear *Back*. 
. In the *Min* box, enter the minimum character length for a new token. 
. In the *Max* box, enter the maximum character length for a new token.
. Click btn:[Submit].

[#elision]
=== Create a Custom `elision` Token Filter

include::partial$custom-token-filters-descriptions.adoc[tags=elision;!elision_example]

To create a new `elision` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *elision*. 
. In the *Articles* list, select a wordlist to use to find elisions in input tokens.
+
You can choose your own xref:create-custom-wordlist.adoc[custom wordlist] or a xref:default-wordlists-reference.adoc[default wordlist].
. Click btn:[Submit]. 

[#keyword-marker]
=== Create a Custom `keyword_marker` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[tags=keyword;!keyword_example]

To create a new `keyword_marker` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *keyword_marker*. 
. In the *Articles* list, select a wordlist to use to find keywords to create tokens.
+
You can choose your own xref:create-custom-wordlist.adoc[custom wordlist] or a xref:default-wordlists-reference.adoc[default wordlist].
. Click btn:[Submit]. 

[#length]
=== Create a Custom `length` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[tags=length;!length_example]

To create a new `length` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *length*. 
. In the *Min* box, enter the minimum character length for a new token. 
. In the *Max* box, enter the maximum character length for a new token.
. Click btn:[Submit].

[#ngram]
=== Create a Custom `ngram` Token Filter

include::partial$custom-token-filters-descriptions.adoc[tags=ngram;!ngram_example]

To create a new `ngram` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *ngram*. 
. In the *Min* box, enter the minimum character length for a new token. 
. In the *Max* box, enter the maximum character length for a new token.
. Click btn:[Submit].

[#normalize-unicode]
=== Create a Custom `normalize_unicode` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[tags=normalize;!normalize_example]

To create a new `normalize_unicode` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *normalize_unicode*. 
. In the *Form* list, select the type of Unicode normalization to apply: 
+
* *nfc*: Use canonical decomposition and canonical composition to normalize characters. The token filter separates combined unicode characters, then merges them into a single character.
* *nfd*: Use canonical decomposition to normalize characters. The token filter separates combined unicode characters.
* *nfkc*: Use compatibility decomposition to normalize characters. The token filter converts unicode characters to remove variants.
* *nfkd*: Use compatibility decomposition and canonical composition to normalize characters. The token filter removes variants, then separates combined unicode characters to merge them into a single character.
. Click btn:[Submit].

[#shingle]
=== Create a Custom `shingle` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[tags=shingle;!shingle_example]

To create a new `shingle` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *shingle*.
. In the *Min* box, enter the minimum character length for a new token before concatenation. 
. In the *Max* box, enter the maximum character length for a new token before concatenation.
. Do one of the following: 
.. To include the original token as an output token, select *Include original token*. 
.. To remove the original token from output, clear *Include original token*. 
. (Optional) In the *Separator* field, enter a character or characters to add in between concatenated tokens. 
. (Optional) In the *Filler* field, enter a character or characters to replace tokens that are removed by another token filter.
. Click btn:[Submit].

[#stop-tokens]
=== Create a Custom `stop_tokens` Token Filter

include::partial$custom-token-filters-descriptions.adoc[tags=stop;!stop_example]

To create a new `stop_tokens` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *stop_tokens*. 
. In the *Stop Words* list, select a wordlist to use to remove tokens.
+
You can choose your own xref:create-custom-wordlist.adoc[custom wordlist] or a xref:default-wordlists-reference.adoc[default wordlist].
. Click btn:[Submit].

[#truncate-token]
=== Create a Custom `truncate_token` Token Filter 

include::partial$custom-token-filters-descriptions.adoc[tags=truncate;!truncate_example]

To create a new `truncate_token` token filter with the {page-ui-name} in Advanced Mode:

. In the *Type* list, select *truncate_token*.
. In the *Length* box, enter the maximum character length for an output token. 
. Click btn:[Submit].

== Next Steps

After you create a custom token filter, you can use it with xref:create-custom-analyzer.adoc[a custom analyzer]. 

To continue customizing your Search index, you can also: 

* xref:set-advanced-settings.adoc[]
* xref:set-type-identifier.adoc[]
* xref:create-type-mapping.adoc[]
* xref:create-child-field.adoc[]
* xref:create-child-mapping.adoc[]
* xref:create-custom-analyzer.adoc[]
* xref:create-custom-character-filter.adoc[]
* xref:create-custom-tokenizer.adoc[]
* xref:create-custom-wordlist.adoc[]

To run a search and test the contents of your Search index, see xref:simple-search-ui.adoc[] or xref:simple-search-rest-api.adoc[].