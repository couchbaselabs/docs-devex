= Default Tokenizers
:page-topic-type: reference
:page-ui-name: {ui-name}
:page-product-name: {product-name}
:description: Tokenizers control how the Search Service splits input strings into individual tokens. 

[abstract]
{description}

You can use a xref:customize-index.adoc#tokenizers[tokenizer] when you xref:create-custom-analyzer.adoc[create a custom analyzer].
Choose a default tokenizer or xref:create-custom-tokenizer.adoc[create your own].

The following default tokenizers are available:

|====
|Tokenizer |Description 

|hebrew |Separates an input string into tokens that contain only Hebrew alphabet characters. Punctuation marks and numbers are excluded.

|letter |Separates an input string into tokens that contain only Latin alphabet characters. Punctuation marks and numbers are excluded.

|single |Creates a single token from the input string. Special characters and whitespace are preserved.

|[[unicode]]unicode |Separates input strings into tokens based on http://www.unicode.org/reports/tr29/#Word_Boundaries[Unicode Word Boundaries^]. 

|web |Creates tokens from an input string that match email address, URL, Twitter username, and hashtag patterns.

|[[whitespace]]whitespace |Separates an input string into tokens based on the location of whitespace characters.

|====