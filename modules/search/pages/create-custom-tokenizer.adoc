= Create a Custom Tokenizer 
:page-topic-type: guide
:page-ui-name: {ui-name}
:page-product-name: {product-name}
:description: Create a custom tokenizer with the Couchbase {page-ui-name} to change how the Search Service creates tokens for matching Search index content to a Search query.
:page-toclevels: 3

[abstract]
{description}

== Prerequisites 

* You have the Search Service enabled on a node in your database.
For more information about how to change Services on your database, see xref:cloud:clusters:modify-database.adoc[].

 
* You have logged in to the Couchbase {page-ui-name}. 

* You have started to create or already created an index in xref:create-search-indexes.adoc#advanced-mode[Advanced Mode Editing].

* You have already created or started to create a xref:create-custom-analyzer.adoc[custom analyzer] in your Search index.

== Procedure

To create a new custom tokenizer with the {page-ui-name} in Advanced Mode:

. On the *Databases* page, select the database that has the Search index you want to edit. 
. Go to menu:Data Tools[Search].
. Click the index where you want to create a custom tokenizer.
. (Optional) If you did not create your index with Advanced Mode, select *Enable Advanced Options*.
. Expand *Global Index Settings*.
. Do one of the following: 
.. To create a new custom analyzer with a new tokenizer, click btn:[Add Custom Analyzer].
.. To add a new custom tokenizer to use with an existing analyzer, expand the *Default Analyzer* list, and next to your custom analyzer, click btn:[Edit].
. Click btn:[Add Custom Tokenizer].
. In the *Tokenizer Name* field, enter a name for the tokenizer.
. In the *Type* list, select a tokenizer type.
. Configure your tokenizer based on your chosen tokenizer type.

You can create 2 types of custom tokenizers: 

|====
|Tokenizer Type |Description

|<<regexp,Regular expression>> |The tokenizer uses any input that matches the regular expression to create new tokens. 

|<<excep,Exception>> |The tokenizer removes any input that matches the regular expression, and creates tokens from the remaining input.
You can choose another tokenizer to apply to the remaining input.

|====

[#regexp]
=== Create a Regular Expression Tokenizer

To create a regular expression tokenizer with the {page-ui-name}:

. In the *Type* list, select *regexp*.
. In the *Regular Expression* field, enter the regular expression to use to split input into tokens.
+
For example, the regular expression `\b\w+\b` would create tokens based on the word boundaries and word characters found in the input. 
. Click btn:[Add Custom Tokenizer].

[#excep]
=== Create an Exception Custom Tokenizer 

To create an exception custom tokenizer with the {page-ui-name} in Advanced Mode:
 
. In the *Type* list, select *exception*.
. In the *Regular Expressions* field, enter 1 or more regular expression to use to remove content from your input.
Separate multiple regular expression patterns by entering a comma (`,`).
. In the *Tokenizer for Remaining Input* list, select a tokenizer to apply to your input after removing any content that matches your provided *Regular Expressions*.
+
For more information about the available tokenizers, see xref:default-tokenizers-reference.adoc[].
. Click btn:[Add Custom Tokenizer].

== Next Steps

After you create a custom tokenizer, you can use it with xref:create-custom-analyzer.adoc[a custom analyzer].

To continue customizing your Search index, you can also: 

* xref:set-type-identifier.adoc[]
* xref:create-custom-character-filter.adoc[]
* xref:create-custom-token-filter.adoc[]

To run a search and test the contents of your Search index, see xref:simple-search-ui.adoc[].