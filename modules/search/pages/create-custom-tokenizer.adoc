= Create a Custom Tokenizer 
:page-topic-type: guide
:description: Create a custom tokenizer with the Couchbase Server Web Console to change how the Search Service creates tokens for matching Search index content to a Search query.
:page-toclevels: 3

[abstract]
{description}

== Prerequisites 

* You have the Search Service enabled on a node in your database.
For more information about how to deploy a new node and Services on your database, see xref:server:manage:manage-nodes/node-management-overview.adoc[].

* You have created an index.
For more information, see xref:create-search-index-ui.adoc[].

* You have logged in to the Couchbase Server Web Console. 

== Procedure

You can create 2 types of custom tokenizers: 

|====
|Tokenizer Type |Description

|<<regexp,Regular expression>> |The tokenizer uses any input that matches the regular expression to create new tokens. 

|<<excep,Exception>>  |The tokenizer removes any input that matches the regular expression, and creates tokens from the remaining input. You can choose another tokenizer to apply to the remaining input.

|====

[#regexp]
=== Create a Regular Expression Tokenizer

To create a regular expression tokenizer with the Couchbase Server Web Console: 

. Go to *Search*. 
. Click the Search index where you want to create a custom tokenizer.
. Click btn:[Edit].
. Expand menu:Customize Index[Custom Filters]. 
. Click btn:[Add Tokenizer].
. In the *Name* field, enter a name for the custom tokenizer. 
. In the *Type* field, select *regexp*.
. In the *Regular Expression* field, enter the regular expression to use to split input into tokens. 
. Click btn:[Save].

[#excep]
=== Create an Exception Custom Tokenizer 

To create an exception custom tokenizer with the Couchbase Server Web Console: 

. Go to *Search*. 
. Do one of the following: 
. Click the Search index where you want to create a custom tokenizer.
. Click btn:[Edit].
. Expand menu:Customize Index[Custom Filters]. 
. Click btn:[Add Tokenizer].
. In the *Name* field, enter a name for the custom tokenizer. 
. In the *Type* field, select *exception*.
. In the *Exception Patterns* field, enter a regular expression to use to remove content from input.
. To add the regular expression to the list of exception patterns, click btn:[Add].
. (Optional) To add additional regular expressions to the list of exception patterns, repeat the previous steps.
. In the *Tokenizer for Remaining Input* field, select a tokenizer to apply to input after removing any content that matches the regular expression.
+
For more information about the available tokenizers, see xref:default-tokenizers-reference.adoc[].
. Click btn:[Save].

== Next Steps

After you create a custom tokenizer, you can use it with xref:create-custom-analyzer.adoc[a custom analyzer].

To continue customizing your Search index, you can also: 

* xref:set-type-identifier.adoc[]
* xref:create-type-mapping.adoc[]
* xref:create-child-field.adoc[]
* xref:create-child-mapping.adoc[]
* xref:create-custom-character-filter.adoc[]
* xref:create-custom-token-filter.adoc[]
* xref:create-custom-wordlist.adoc[]
* xref:set-advanced-settings.adoc[]

To run a search and test the contents of your Search index, see xref:simple-search-ui.adoc[] or xref:simple-search-rest-api.adoc[].