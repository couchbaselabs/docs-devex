= Use Vector Search for AI Applications
:page-topic-type: concept
:description: Use Couchbase Capella's Vector Search features to add fast and accurate semantic search to your applications.

[abstract]
{description}

== About Vector Search

Vector Search builds on Capella's xref:search.adoc[Search Service] to provide vector index support.
You can use these new Vector Search indexes for Retrieval Augmented Generation (RAG) with an existing Large Language Model (LLM). 

Using Vector Search, Couchbase Server, an embedding model, and your chosen LLM, you can develop AI applications while giving context and up-to-date information from your own data.

You can develop applications that include: 

* *Similarity search:* Search for documents, products, images, and more that are similar to a given query.
Using vector embeddings to represent data, your end users can search based on descriptions, rather than using specific keywords.

* *Generative AI:* Create new text, images, and more based on a prompt given to the LLM.  

// More use cases worth calling out?

Vector Search supports integrations with frameworks like https://python.langchain.com/docs/get_started/introduction[LangChain^] to support AI application development. 
For more information about all frameworks and integrations supported by Vector Search and Capella, see xref:[].
//Don't forget to fill in this link!

== Using Vector Search Indexes

Use a Couchbase Capella database to store the data you want to use to provide context to a LLM. 
Generate vector embeddings using your preferred embedding model, then store the embeddings in an array inside your documents. 

Create a Vector Search index to use the vector embeddings from your data and find matches from a search query's generated vectors.

If you do not want to use an integration like LangChain, you can also use the API for an existing LLM and one of their embedding models to generate these embeddings for your data.
For example, the OpenAI `embeddings` endpoint can generate embeddings for a text string using a specified embedding model.
For more information about how to generate and obtain embeddings for text strings using the OpenAI API, see the https://platform.openai.com/docs/guides/embeddings/what-are-embeddings[Embeddings documentation].

NOTE: When creating a Vector Search index, the dimension of your data vector embeddings must match the dimension for any search query vectors.

For more information about how to create a Vector Search index, see xref:[].
For information about how to run a Vector Search query, see xref:[].
// Don't forget to provide these links! And add to See Also

== See Also

* xref:search:search.adoc[]