= Use Vector Search for AI Applications
:page-topic-type: concept
:description: Use Couchbase Capella's Vector Search features to add fast and accurate similarity and semantic search to your applications.

[abstract]
{description}

== About Vector Search

Vector Search builds on Couchbase Capella's xref:search:search.adoc[Search Service] to provide vector index support.
You can use these new Vector Search indexes for Retrieval Augmented Generation (RAG) with an existing Large Language Model (LLM). 

Using Capella's Vector Search, an embedding model, and your chosen LLM, you can develop AI applications while giving context and up-to-date information from your own data.

You can develop applications that include: 

* *Similarity Search:* Search for documents, products, images, and more that are similar to a query using vector embeddings. 
This allows searches based on descriptions rather than specific keywords, facilitating intuitive and relevant results across various data types.

* *Semantic Search:* Understand the intent and context behind queries with semantic search, leveraging natural language processing to deliver more accurate results. 
It extends beyond keyword matches to interpret the meaning of text and, increasingly, other media types.

* *Generative AI:* Leverage Generative AI with LLMs and embedding models to produce original, contextually relevant content, including text and images, from user prompts or vector searches. 
This approach ensures tailored and dynamic responses across various applications.

Vector Search supports integrations with frameworks like https://python.langchain.com/docs/get_started/introduction[LangChain^] and https://docs.llamaindex.ai/en/stable/[LlamaIndex^] to support AI application development. 
For more information about all frameworks and integrations supported by Vector Search and Capella, see xref:third-party:integrations.adoc[].

== Using Vector Search Indexes

You can get started using Vector Search in Capella by: 

. Store Data: Begin by using a Capella database to store your raw data, laying the foundation for advanced search and AI capabilities.
. Generate Embeddings: Generate vector embeddings from your data using a preferred embedding model, encapsulating the semantic essence of your documents.
. Embeddings Storage: Store these vector embeddings in an array or vector within your documents, enabling efficient retrieval and similarity comparisons.
. Create Vector Index: Create a Vector Search index to leverage these embeddings, facilitating the identification of similar documents based on vector similarity.

In addition to supporting integrations with frameworks like LangChain and LlamaIndex, Capella enables you to leverage APIs from established LLMs, along with their embedding models, to generate vector embeddings for your data.
For example, the OpenAI `embeddings` endpoint can generate embeddings for a text strings using a specified embedding model which is then stored as a new field in your documents. 
For more information about how to generate and obtain embeddings for text strings using the OpenAI API, see the https://platform.openai.com/docs/guides/embeddings/what-are-embeddings[Embeddings documentation].

NOTE: When you create a Vector Search index, the xref:search:child-field-options-reference.adoc#dimension[dimension] of your data vector embeddings must match the dimension for any search query vectors.
Otherwise, a Vector Search query fails to return any results.

For more information about how to create a Vector Search index, see xref:create-vector-search-index-ui.adoc[] or xref:create-vector-search-index-rest-api.adoc[].

For information about how to run a Vector Search query, see xref:run-vector-search-ui.adoc[] or xref:run-vector-search-rest-api.adoc[].

For an example on how to run semantic queries with Vector Search via large embedding vectors, see xref:run-vector-search-large-embeddings.adoc[].

For a few examples on how to use the Couchbase Python SDK to run Vector Search, see xref:run-vector-search-from-python-sdk.adoc[].

== See Also

* xref:search:search.adoc[]
* xref:create-vector-search-index-ui.adoc[]
* xref:create-vector-search-index-rest-api.adoc[]
* xref:run-vector-search-ui.adoc[] 
* xref:run-vector-search-rest-api.adoc[]
