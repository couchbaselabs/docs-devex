= Use Vector Search for AI Applications
:page-topic-type: concept
:description: Use Couchbase Capella's Vector Search features to add fast and accurate semantic search to your applications.

[abstract]
{description}

== About Vector Search

Vector Search builds on Couchbase Capella's xref:search:search.adoc[Search Service] to provide vector index support.
You can use these new Vector Search indexes for Retrieval Augmented Generation (RAG) with an existing Large Language Model (LLM). 

Using Vector Search, Capella, an embedding model, and your chosen LLM, you can develop AI applications while giving context and up-to-date information from your own data.

You can develop applications that include: 

* *Similarity search:* Search for documents, products, images, and more that are similar to a given query.
Using vector embeddings to represent data, your end users can search based on descriptions, rather than using specific keywords.

* *Generative AI:* Create new text, images, and more based on a prompt given to the LLM.  

Vector Search supports integrations with frameworks like https://python.langchain.com/docs/get_started/introduction[LangChain^] to support AI application development. 
For more information about all frameworks and integrations supported by Vector Search and Capella, see xref:third-party:integrations.adoc[].

== Using Vector Search Indexes

You can get started using Vector Search in Capella by: 

. Using a Capella database to store the data you want to use to provide context to a LLM. 
. Generating vector embeddings using your preferred embedding model, then storing the embeddings in an array inside your documents. 
. Creating a Vector Search index to use the vector embeddings from your data and find matches from a search query's generated vectors.

In addition to supporting integrations with frameworks like LangChain, you can also use the API for an existing LLM and one of their embedding models to generate these embeddings for your data.
For example, the OpenAI `embeddings` endpoint can generate embeddings for a text string using a specified embedding model. 
For more information about how to generate and obtain embeddings for text strings using the OpenAI API, see the https://platform.openai.com/docs/guides/embeddings/what-are-embeddings[Embeddings documentation].

NOTE: When you create a Vector Search index, the xref:search:child-field-options-reference.adoc#dimension[dimension] of your data vector embeddings must match the dimension for any search query vectors.
Otherwise, a Vector Search query fails to return any results.

For more information about how to create a Vector Search index, see xref:create-vector-search-index-ui.adoc[] or xref:create-vector-search-index-rest-api.adoc[].

For information about how to run a Vector Search query, see xref:run-vector-search-ui.adoc[] or xref:run-vector-search-rest-api.adoc[].

== See Also

* xref:search:search.adoc[]
* xref:create-vector-search-index-ui.adoc[]
* xref:create-vector-search-index-rest-api.adoc[]
* xref:run-vector-search-ui.adoc[] 
* xref:run-vector-search-rest-api.adoc[]