= Run a Vector Search using the Python SDK 
:page-topic-type: guide 
:description: Performing Vector Search via the Python SDK.

[abstract]
{description}

== Prerequisites 

* You have the Search Service enabled on a node in your database.
For more information about how to change Services on your database, see xref:cloud:clusters:modify-database.adoc[].

// * Your user account has the *Search Admin* or *Search Reader* role. 

* You have the hostname for your a node in your cluster running the Search service.  This typically is different than the hostname found in the `Public Connection String` under Connect. 
You can find a list of all  Nodes under Settings. 

//For more information about how to find the hostname for your Capella database, see xref:clouds:get-capella-host-name.adoc[].

* You have imported data from `rgb.json` into the keyspace `vector-sample.color.rgb` and also `rgb_questions.json` into the keyspace `vector-sample.color.rgb_questions`, see xref:importing-vector-data.adoc[].

* You have created a Vector Search index. To ensure this example works you may want to drop color-index (if it exists) and re-create it via the REST API.
+
For more information about how to create a Vector Search index, see xref:create-vector-search-index-ui.adoc[] or xref:create-vector-search-index-rest-api.adoc[].

* You probably want to create and activate a virtual environment using the standard libraryâ€™s virtual environment tool venv and install packages.
+
https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/

* Install dependencies
+
Make a file `requirements.txt`
+
[source,console]
----
couchbase==4.1.12
openai==1.12.0
----
+
`pip install -r requirements.txt`

== Overview

Embedding vectors, may be quite small for example when searching for colors.
  
However for natural langage processing (NLP) the embedding vectorswhich are used for similarity and semantic search, are typically created using an embedding model.

Below are two Python programs to demonstrate how to use Couchbase SDKs. However, you need an API key linked to a paid subscription to OpenAI for the second program.

== Searching for a color
                                                                                                         
For the sample vector dataset "rgb.json", we have already generated small embedding vectors for the "colorvect_l2" field.
These are vectors decimal floats for example red would be [255.0, 0.0, 0.0] and navy would be [0.0, 0.0, 128.0].
The program below will search for navy in the sample vector dataset "rgb.json".

[source,console]
----
#!/usr/bin/env python3

import os
import sys
from couchbase.cluster import Cluster
from couchbase.options import ClusterOptions
from couchbase.auth import PasswordAuthenticator
from couchbase.exceptions import CouchbaseException
import couchbase.search as search
from couchbase.options import SearchOptions
from couchbase.vector_search import VectorQuery, VectorSearch

# Change the RGB values as desired
vector = [0.0,0.0,128.0]
                                                                                                         
pa = PasswordAuthenticator(os.getenv("CB_USERNAME"), os.getenv("CB_PASSWORD"))
cluster = Cluster("couchbases://" + os.getenv("CB_HOSTNAME") + "/?ssl=no_verify", ClusterOptions(pa))

bucket = cluster.bucket("vector-sample")
scope = bucket.scope("color")
search_index = "color-index"

try:
    search_req = search.SearchRequest.create(search.MatchNoneQuery()).with_vector_search(
        VectorSearch.from_vector_query(VectorQuery('colorvect_l2', vector, num_candidates=3)))

    result = scope.search(search_index, search_req, SearchOptions(limit=13,fields=["color", "id"]))

    for row in result.rows():
        print("Found row: {}".format(row))

    print("Reported total rows: {}".format(
        result.metadata().metrics().total_rows()))

except CouchbaseException as ex:
    import traceback
    traceback.print_exc()
----

Try changing `vector` in the code to differing RGB values like  [0.0,0.0,127.0] or  [255.0, 140.0, 59.0].

== Searching for a similar dscription

For the sample vector dataset "rgb.json", we have already generated embedding vectors for the "description" field. 
Now instead of copying the query of the vector from "rgb_questions.json", we will use a paid service from OpenAI to generate any question you want.

[source,console]
----
#!/usr/bin/env python3

import os
import sys
from couchbase.cluster import Cluster
from couchbase.options import ClusterOptions
from couchbase.auth import PasswordAuthenticator
from couchbase.exceptions import CouchbaseException
import couchbase.search as search
from couchbase.options import SearchOptions
from couchbase.vector_search import VectorQuery, VectorSearch
from openai import OpenAI

# Change the question as desired
question = "What color hides everything like the night?"

openai_api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI()

pa = PasswordAuthenticator(os.getenv("CB_USERNAME"), os.getenv("CB_PASSWORD"))
cluster = Cluster("couchbases://" + os.getenv("CB_HOSTNAME") + "/?ssl=no_verify", ClusterOptions(pa))

bucket = cluster.bucket("vector-sample")
scope = bucket.scope("color")
search_index = "color-index"

try:
    vector = client.embeddings.create(input = [question], model="text-embedding-ada-002").data[0].embedding

    search_req = search.SearchRequest.create(search.MatchNoneQuery()).with_vector_search(
        VectorSearch.from_vector_query(VectorQuery('embedding_vector_dot', vector, num_candidates=2)))

    result = scope.search(search_index, search_req, SearchOptions(limit=13,fields=["color", "description"]))

    for row in result.rows():
        print("Found row: {}".format(row))

    print("Reported total rows: {}".format(
        result.metadata().metrics().total_rows()))

except CouchbaseException as ex:
    import traceback
    traceback.print_exc()
----

Try changing `question` in the code to different text like:

* "What is the most romantic color?"

* "What color makes people fall in love?"

* "What is the most depressing color?"

If you do not get the search results you were expecting, reread the prerequsites and recreate the index via the REST API.

You can also xref:search:customize-index.adoc[].
